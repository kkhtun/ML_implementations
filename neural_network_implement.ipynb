{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_network_implement.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2uJWYdMvetR"
      },
      "source": [
        "This code sheet is my attempt to implement a plain neural network from scratch and proving that hidden layers (including deep neural networks) are essential in learning non-linear functions that we see in most of our real-world data  \n",
        "A neural network without a hidden layer is unable to learn a non-linear XOR function as described below  \n",
        "Reference: www.pyimagesearch.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chsa7CIGcnGu"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHBBUCPzcwZ4"
      },
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, layers, alpha = 0.1):\n",
        "    self.W = []\n",
        "    self.layers = layers\n",
        "    self.alpha = alpha\n",
        "\n",
        "    for i in np.arange(0, len(layers)-2):\n",
        "      w = np.random.randn(layers[i]+1, layers[i+1]+1) / np.sqrt(layers[i])\n",
        "      self.W.append(w)\n",
        "\n",
        "    w = np.random.randn(layers[-2]+1, layers[-1]) / np.sqrt(layers[-2])\n",
        "    self.W.append(w)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return \"Neural Network : {}\".format(\"-\".join(str(l) for l in self.layers))\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "  def d_sigmoid(self, x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "\n",
        "  def fit(self, X, Y, epoch = 1000, displayUpdate = 1000):\n",
        "\n",
        "    X = np.c_[X, np.ones((X.shape[0]))]\n",
        "\n",
        "    for i in np.arange(0, epoch):\n",
        "      for (x, y) in zip(X, Y):\n",
        "        self.fit_partial(x, y)\n",
        "      if i == 0 or (i+1) % displayUpdate == 0:\n",
        "        loss = self.compute_loss(X, Y)\n",
        "        print(\"Epoch {}, Loss {:.7f}\".format(i+1, loss))\n",
        "\n",
        "\n",
        "  def fit_partial(self, x, y):\n",
        "\n",
        "    A = [np.atleast_2d(x)]\n",
        "\n",
        "    for layer_no in np.arange(0, len(self.W)):\n",
        "      \n",
        "      h = A[layer_no].dot(self.W[layer_no])\n",
        "      a = self.sigmoid(h)\n",
        "      A.append(a)\n",
        "\n",
        "    error = A[-1] - y\n",
        "    D = [error * self.d_sigmoid(A[-1])]\n",
        "\n",
        "    for layer_no in np.arange(len(A)-2, 0, -1):\n",
        "      delta = (D[-1].dot(self.W[layer_no].T)) * self.d_sigmoid(A[layer_no])\n",
        "      D.append(delta)\n",
        "\n",
        "    D = D[::-1]\n",
        "\n",
        "    for layer_no in np.arange(0, len(self.W)):\n",
        "      self.W[layer_no] += -self.alpha * A[layer_no].T.dot(D[layer_no])\n",
        "\n",
        "\n",
        "  def predict(self, X, addBias = True):\n",
        "    p = np.atleast_2d(X)\n",
        "\n",
        "    if addBias:\n",
        "      p = np.c_[p, np.ones((p.shape[0]))]\n",
        "    \n",
        "    for layer_no in np.arange(0, len(self.W)):\n",
        "      p = self.sigmoid(np.dot(p, self.W[layer_no]))\n",
        "    return p\n",
        "\n",
        "  def compute_loss(self, X, Y):\n",
        "\n",
        "    Y = np.atleast_2d(Y)\n",
        "    preds = self.predict(X, addBias = False)\n",
        "    loss = np.sum(np.square(preds - Y))/2\n",
        "    return loss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg2MdH_Gcwje",
        "outputId": "e4b8c1d6-8ff7-4040-e9da-bf5d2130fa8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NeuralNetwork([2,2,1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Neural Network : 2-2-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibZVf3QYuzZT"
      },
      "source": [
        "Training the neural network on XOR function using a single hidden layer [2-2-1] architecture   \n",
        "Please do note that neural network is able to predict the non-linear XOR function correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hpfih7peNKk",
        "outputId": "b370a511-5bd3-4673-e758-31d2d8946ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "nn = NeuralNetwork([2,2,1], alpha = 0.5)\n",
        "nn.fit(X, Y, epoch = 20000)\n",
        "\n",
        "for (x, y) in zip(X,Y):\n",
        "\n",
        "  pred = nn.predict(x)[0][0]\n",
        "  step = 1 if pred > 0.5 else 0\n",
        "  print(\"Data {}, Ground Truth {} Prediction {} Step {}\".format(x, y, pred, step))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss 0.5166495\n",
            "Epoch 1000, Loss 0.2523390\n",
            "Epoch 2000, Loss 0.0071080\n",
            "Epoch 3000, Loss 0.0029031\n",
            "Epoch 4000, Loss 0.0018016\n",
            "Epoch 5000, Loss 0.0013022\n",
            "Epoch 6000, Loss 0.0010184\n",
            "Epoch 7000, Loss 0.0008357\n",
            "Epoch 8000, Loss 0.0007084\n",
            "Epoch 9000, Loss 0.0006146\n",
            "Epoch 10000, Loss 0.0005426\n",
            "Epoch 11000, Loss 0.0004857\n",
            "Epoch 12000, Loss 0.0004396\n",
            "Epoch 13000, Loss 0.0004014\n",
            "Epoch 14000, Loss 0.0003693\n",
            "Epoch 15000, Loss 0.0003419\n",
            "Epoch 16000, Loss 0.0003183\n",
            "Epoch 17000, Loss 0.0002978\n",
            "Epoch 18000, Loss 0.0002797\n",
            "Epoch 19000, Loss 0.0002637\n",
            "Epoch 20000, Loss 0.0002494\n",
            "Data [0 0], Ground Truth [0] Prediction 0.01118402167124236 Step 0\n",
            "Data [0 1], Ground Truth [1] Prediction 0.9946305738127579 Step 1\n",
            "Data [1 0], Ground Truth [1] Prediction 0.9854332648170621 Step 1\n",
            "Data [1 1], Ground Truth [0] Prediction 0.011520151727963304 Step 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG_t05n5vGld"
      },
      "source": [
        "Training the neural network on XOR function with no hidden layers (only the input and output layer, just like a simple perceptron unit)  \n",
        "Here, the neural network fails to learn a non-linear XOR function as predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVoYfGvNt5z-",
        "outputId": "d9b6aeca-40b9-4c3f-b9bd-bd134caac518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "nn_single_layer = NeuralNetwork([2, 1], alpha=0.5)\n",
        "nn_single_layer.fit(X, Y, epoch=20000)\n",
        "\n",
        "for (x, y) in zip(X,Y):\n",
        "\n",
        "  pred = nn_single_layer.predict(x)[0][0]\n",
        "  step = 1 if pred > 0.5 else 0\n",
        "  print(\"Data {}, Ground Truth {} Prediction {} Step {}\".format(x, y, pred, step))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss 0.5241992\n",
            "Epoch 1000, Loss 0.5007938\n",
            "Epoch 2000, Loss 0.5007938\n",
            "Epoch 3000, Loss 0.5007938\n",
            "Epoch 4000, Loss 0.5007938\n",
            "Epoch 5000, Loss 0.5007938\n",
            "Epoch 6000, Loss 0.5007938\n",
            "Epoch 7000, Loss 0.5007938\n",
            "Epoch 8000, Loss 0.5007938\n",
            "Epoch 9000, Loss 0.5007938\n",
            "Epoch 10000, Loss 0.5007938\n",
            "Epoch 11000, Loss 0.5007938\n",
            "Epoch 12000, Loss 0.5007938\n",
            "Epoch 13000, Loss 0.5007938\n",
            "Epoch 14000, Loss 0.5007938\n",
            "Epoch 15000, Loss 0.5007938\n",
            "Epoch 16000, Loss 0.5007938\n",
            "Epoch 17000, Loss 0.5007938\n",
            "Epoch 18000, Loss 0.5007938\n",
            "Epoch 19000, Loss 0.5007938\n",
            "Epoch 20000, Loss 0.5007938\n",
            "Data [0 0], Ground Truth [0] Prediction 0.51610600358629 Step 1\n",
            "Data [0 1], Ground Truth [1] Prediction 0.5 Step 0\n",
            "Data [1 0], Ground Truth [1] Prediction 0.4838939964137099 Step 0\n",
            "Data [1 1], Ground Truth [0] Prediction 0.46782138179306076 Step 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-UZe3IxHUL7"
      },
      "source": [
        "Training and testing the created neural network on a subset of MNIST hand-written digits data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6jSKI9vBYhD"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ndvuUJBt5A",
        "outputId": "a23f93fb-37b3-4aa2-b7f3-c892630249f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "digits = datasets.load_digits()\n",
        "data = digits.data.astype(\"float\")\n",
        "data = (data - data.min())/(data.max()-data.min())\n",
        "print(\"No of Examples {}, Dimension {}.\".format(data.shape[0],data.shape[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of Examples 1797, Dimension 64.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9LVP1jTCe7N",
        "outputId": "0061233d-7da0-4d48-ed22-50819eb4278e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_X, test_X, train_Y, test_Y = train_test_split(data, digits.target, test_size = 0.25)\n",
        "print(train_X.shape, train_Y.shape)\n",
        "\n",
        "train_Y = LabelBinarizer().fit_transform(train_Y)\n",
        "test_Y = LabelBinarizer().fit_transform(test_Y)\n",
        "print(train_X.shape, train_Y.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1347, 64) (1347,)\n",
            "(1347, 64) (1347, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SXM-kC8Dsl3",
        "outputId": "60fec2aa-d599-4012-f524-8bad9afe0a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(\"Training neural network...\")\n",
        "nn = NeuralNetwork([train_X.shape[1],32,16,10])\n",
        "print(\"Layer info of {}\".format(nn))\n",
        "nn.fit(train_X, train_Y, epoch=1000, displayUpdate = 100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training neural network...\n",
            "Layer info of Neural Network : 64-32-16-10\n",
            "Epoch 1, Loss 605.4132198\n",
            "Epoch 100, Loss 6.6015819\n",
            "Epoch 200, Loss 2.9785251\n",
            "Epoch 300, Loss 2.5117352\n",
            "Epoch 400, Loss 2.3399467\n",
            "Epoch 500, Loss 2.2514718\n",
            "Epoch 600, Loss 2.1952869\n",
            "Epoch 700, Loss 1.7046182\n",
            "Epoch 800, Loss 1.6584573\n",
            "Epoch 900, Loss 1.6319657\n",
            "Epoch 1000, Loss 1.6126860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbSJ6gXCErma",
        "outputId": "d25fa43e-9b66-4ebb-f542-5c3aef13c9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(\"Predicting the trained network...\")\n",
        "preds = nn.predict(test_X)\n",
        "preds = preds.argmax(axis = 1)\n",
        "print(classification_report(test_Y.argmax(axis = 1), preds))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting the trained network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        45\n",
            "           1       1.00      1.00      1.00        52\n",
            "           2       1.00      0.98      0.99        54\n",
            "           3       1.00      0.98      0.99        55\n",
            "           4       0.98      0.96      0.97        49\n",
            "           5       0.97      0.97      0.97        39\n",
            "           6       1.00      1.00      1.00        43\n",
            "           7       0.98      0.98      0.98        45\n",
            "           8       1.00      1.00      1.00        35\n",
            "           9       0.89      1.00      0.94        33\n",
            "\n",
            "    accuracy                           0.98       450\n",
            "   macro avg       0.98      0.99      0.98       450\n",
            "weighted avg       0.99      0.98      0.98       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERvv8G6oHIZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}